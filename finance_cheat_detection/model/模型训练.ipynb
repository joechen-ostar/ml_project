{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置字符集，防止图片中的中文乱码\n",
    "mpl.rcParams['font.sans-serif']=[u'simHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置jupyter图片显示方式\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10.65</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>15.27</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>15.96</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  int_rate  annual_inc  loan_status    dti  delinq_2yrs  \\\n",
       "0     5000.0     10.65     24000.0          1.0  27.65          0.0   \n",
       "1     2500.0     15.27     30000.0          0.0   1.00          0.0   \n",
       "2     2400.0     15.96     12252.0          1.0   8.72          0.0   \n",
       "\n",
       "   inq_last_6mths  mths_since_last_delinq  open_acc  pub_rec  \\\n",
       "0             1.0                     0.0       3.0      0.0   \n",
       "1             5.0                     0.0       3.0      0.0   \n",
       "2             2.0                     0.0       2.0      0.0   \n",
       "\n",
       "            ...            purpose_major_purchase  purpose_medical  \\\n",
       "0           ...                                 0                0   \n",
       "1           ...                                 0                0   \n",
       "2           ...                                 0                0   \n",
       "\n",
       "   purpose_moving  purpose_other  purpose_renewable_energy  \\\n",
       "0               0              0                         0   \n",
       "1               0              0                         0   \n",
       "2               0              0                         0   \n",
       "\n",
       "   purpose_small_business  purpose_vacation  purpose_wedding  \\\n",
       "0                       0                 0                0   \n",
       "1                       0                 0                0   \n",
       "2                       1                 0                0   \n",
       "\n",
       "   debt_settlement_flag_N  debt_settlement_flag_Y  \n",
       "0                       1                       0  \n",
       "1                       1                       0  \n",
       "2                       1                       0  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特征之后的数据读取\n",
    "data = pd.read_csv(\"../data/features01.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39786 entries, 0 to 39785\n",
      "Data columns (total 56 columns):\n",
      "loan_amnt                              39786 non-null float64\n",
      "int_rate                               39786 non-null float64\n",
      "annual_inc                             39786 non-null float64\n",
      "loan_status                            39786 non-null float64\n",
      "dti                                    39786 non-null float64\n",
      "delinq_2yrs                            39786 non-null float64\n",
      "inq_last_6mths                         39786 non-null float64\n",
      "mths_since_last_delinq                 39786 non-null float64\n",
      "open_acc                               39786 non-null float64\n",
      "pub_rec                                39786 non-null float64\n",
      "revol_bal                              39786 non-null float64\n",
      "revol_util                             39786 non-null float64\n",
      "total_acc                              39786 non-null float64\n",
      "collections_12_mths_ex_med             39786 non-null float64\n",
      "acc_now_delinq                         39786 non-null float64\n",
      "chargeoff_within_12_mths               39786 non-null float64\n",
      "delinq_amnt                            39786 non-null float64\n",
      "tax_liens                              39786 non-null float64\n",
      "term_ 36 months                        39786 non-null int64\n",
      "term_ 60 months                        39786 non-null int64\n",
      "emp_length_0                           39786 non-null int64\n",
      "emp_length_1                           39786 non-null int64\n",
      "emp_length_10                          39786 non-null int64\n",
      "emp_length_11                          39786 non-null int64\n",
      "emp_length_2                           39786 non-null int64\n",
      "emp_length_3                           39786 non-null int64\n",
      "emp_length_4                           39786 non-null int64\n",
      "emp_length_5                           39786 non-null int64\n",
      "emp_length_6                           39786 non-null int64\n",
      "emp_length_7                           39786 non-null int64\n",
      "emp_length_8                           39786 non-null int64\n",
      "emp_length_9                           39786 non-null int64\n",
      "home_ownership_MORTGAGE                39786 non-null int64\n",
      "home_ownership_NONE                    39786 non-null int64\n",
      "home_ownership_OTHER                   39786 non-null int64\n",
      "home_ownership_OWN                     39786 non-null int64\n",
      "home_ownership_RENT                    39786 non-null int64\n",
      "verification_status_Not Verified       39786 non-null int64\n",
      "verification_status_Source Verified    39786 non-null int64\n",
      "verification_status_Verified           39786 non-null int64\n",
      "purpose_car                            39786 non-null int64\n",
      "purpose_credit_card                    39786 non-null int64\n",
      "purpose_debt_consolidation             39786 non-null int64\n",
      "purpose_educational                    39786 non-null int64\n",
      "purpose_home_improvement               39786 non-null int64\n",
      "purpose_house                          39786 non-null int64\n",
      "purpose_major_purchase                 39786 non-null int64\n",
      "purpose_medical                        39786 non-null int64\n",
      "purpose_moving                         39786 non-null int64\n",
      "purpose_other                          39786 non-null int64\n",
      "purpose_renewable_energy               39786 non-null int64\n",
      "purpose_small_business                 39786 non-null int64\n",
      "purpose_vacation                       39786 non-null int64\n",
      "purpose_wedding                        39786 non-null int64\n",
      "debt_settlement_flag_N                 39786 non-null int64\n",
      "debt_settlement_flag_Y                 39786 non-null int64\n",
      "dtypes: float64(18), int64(38)\n",
      "memory usage: 17.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数量为:39786, 特征属性数量为:55\n"
     ]
    }
   ],
   "source": [
    "# 获取X和Y\n",
    "Y = data['loan_status']\n",
    "X = data.drop(['loan_status'], 1, inplace=False)\n",
    "print(\"样本数量为:%d, 特征属性数量为:%d\" % X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合数据量:31828,55\n",
      "测试集合数据量:7958,55\n"
     ]
    }
   ],
   "source": [
    "# 样本的分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print(\"训练集合数据量:%d,%d\" % x_train.shape)\n",
    "print(\"测试集合数据量:%d,%d\" % x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    27301\n",
      "0.0     4527\n",
      "Name: loan_status, dtype: int64\n",
      "1.0    6815\n",
      "0.0    1143\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 一般情况下：在做分类的时候，都会看一下各个类别的样本数量的比例，看一下是否存在数据的不平衡情况\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优参数:{'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# 首先做一个最优参数的构造\n",
    "parameters = {\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    \"C\": [0.01, 0.1, 1],\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"max_iter\": [100, 150, 200]\n",
    "}\n",
    "clf = GridSearchCV(LogisticRegression(random_state=0), param_grid=parameters, cv=3)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# 得到最优参数\n",
    "print(\"最优参数:\", end=\"\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用逻辑回归来分析数据\n",
    "lr = LogisticRegression(C = 0.1, fit_intercept=True, max_iter=100, penalty='l1', random_state=0)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "train_predict = lr.predict(x_train)\n",
    "test_predict = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据混淆矩阵:\n",
      "[[  111  4416]\n",
      " [   57 27244]]\n",
      "\n",
      "训练数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.02      0.05      4527\n",
      "         1.0       0.86      1.00      0.92     27301\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31828\n",
      "   macro avg       0.76      0.51      0.49     31828\n",
      "weighted avg       0.83      0.86      0.80     31828\n",
      "\n",
      "\n",
      "测试数据混淆矩阵:\n",
      "[[  32 1111]\n",
      " [  12 6803]]\n",
      "\n",
      "测试数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.03      0.05      1143\n",
      "         1.0       0.86      1.00      0.92      6815\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      7958\n",
      "   macro avg       0.79      0.51      0.49      7958\n",
      "weighted avg       0.84      0.86      0.80      7958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_train, train_predict)))\n",
    "print(\"训练数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_train, train_predict)))\n",
    "print(\"测试数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_test, test_predict)))\n",
    "print(\"测试数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_test, test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.9241\n",
      "测试集合上的f1指标:0.9238\n",
      "训练集合上的召回率(y=0):0.0245\n",
      "训练集合上的召回率(y=0):0.0280\n",
      "训练集合上的召回率(y=1):0.9979\n",
      "训练集合上的召回率(y=1):0.9982\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用逻辑回归来分析数据 + 可以选择给类别添加权重\n",
    "weight = {\n",
    "    0: 3, # 在模型训练和测试的过程中，类别0的重要性\n",
    "    1: 1 # 在模型训练和测试的过程中，类别1的重要性\n",
    "}\n",
    "lr = LogisticRegression(C = 0.1, \n",
    "                        fit_intercept=True, \n",
    "                        max_iter=100, \n",
    "                        penalty='l1', \n",
    "                        random_state=0,\n",
    "                        class_weight=weight\n",
    "                       )\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "train_predict = lr.predict(x_train)\n",
    "test_predict = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据混淆矩阵:\n",
      "[[ 1258  3269]\n",
      " [ 2587 24714]]\n",
      "\n",
      "训练数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.28      0.30      4527\n",
      "         1.0       0.88      0.91      0.89     27301\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     31828\n",
      "   macro avg       0.61      0.59      0.60     31828\n",
      "weighted avg       0.80      0.82      0.81     31828\n",
      "\n",
      "\n",
      "测试数据混淆矩阵:\n",
      "[[ 303  840]\n",
      " [ 644 6171]]\n",
      "\n",
      "测试数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.32      0.27      0.29      1143\n",
      "         1.0       0.88      0.91      0.89      6815\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      7958\n",
      "   macro avg       0.60      0.59      0.59      7958\n",
      "weighted avg       0.80      0.81      0.81      7958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_train, train_predict)))\n",
    "print(\"训练数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_train, train_predict)))\n",
    "print(\"测试数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_test, test_predict)))\n",
    "print(\"测试数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_test, test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.8941\n",
      "测试集合上的f1指标:0.8927\n",
      "训练集合上的召回率(y=0):0.2779\n",
      "训练集合上的召回率(y=0):0.2651\n",
      "训练集合上的召回率(y=1):0.9052\n",
      "训练集合上的召回率(y=1):0.9055\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用随机森林来分析数据\n",
    "forest = RandomForestClassifier(random_state=0, max_depth=5)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "train_predict = forest.predict(x_train)\n",
    "test_predict = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据混淆矩阵:\n",
      "[[   68  4459]\n",
      " [    2 27299]]\n",
      "\n",
      "训练数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.02      0.03      4527\n",
      "         1.0       0.86      1.00      0.92     27301\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31828\n",
      "   macro avg       0.92      0.51      0.48     31828\n",
      "weighted avg       0.88      0.86      0.80     31828\n",
      "\n",
      "\n",
      "测试数据混淆矩阵:\n",
      "[[  15 1128]\n",
      " [   3 6812]]\n",
      "\n",
      "测试数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.01      0.03      1143\n",
      "         1.0       0.86      1.00      0.92      6815\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      7958\n",
      "   macro avg       0.85      0.51      0.47      7958\n",
      "weighted avg       0.85      0.86      0.79      7958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_train, train_predict)))\n",
    "print(\"训练数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_train, train_predict)))\n",
    "print(\"测试数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_test, test_predict)))\n",
    "print(\"测试数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_test, test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.9245\n",
      "测试集合上的f1指标:0.9233\n",
      "训练集合上的召回率(y=0):0.0150\n",
      "训练集合上的召回率(y=0):0.0131\n",
      "训练集合上的召回率(y=1):0.9999\n",
      "训练集合上的召回率(y=1):0.9996\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 使用随机森林来分析数据 + 权重\n",
    "weight = {\n",
    "    0: 3, # 在模型训练和测试的过程中，类别0的重要性\n",
    "    1: 1 # 在模型训练和测试的过程中，类别1的重要性\n",
    "}\n",
    "forest = RandomForestClassifier(random_state=0, max_depth=5, class_weight=weight)\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "train_predict = forest.predict(x_train)\n",
    "test_predict = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据混淆矩阵:\n",
      "[[  208  4319]\n",
      " [  170 27131]]\n",
      "\n",
      "训练数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.05      0.08      4527\n",
      "         1.0       0.86      0.99      0.92     27301\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     31828\n",
      "   macro avg       0.71      0.52      0.50     31828\n",
      "weighted avg       0.82      0.86      0.80     31828\n",
      "\n",
      "\n",
      "测试数据混淆矩阵:\n",
      "[[  43 1100]\n",
      " [  56 6759]]\n",
      "\n",
      "测试数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.04      0.07      1143\n",
      "         1.0       0.86      0.99      0.92      6815\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      7958\n",
      "   macro avg       0.65      0.51      0.50      7958\n",
      "weighted avg       0.80      0.85      0.80      7958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_train, train_predict)))\n",
    "print(\"训练数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_train, train_predict)))\n",
    "print(\"测试数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_test, test_predict)))\n",
    "print(\"测试数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_test, test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.9236\n",
      "测试集合上的f1指标:0.9212\n",
      "训练集合上的召回率(y=0):0.0459\n",
      "训练集合上的召回率(y=0):0.0376\n",
      "训练集合上的召回率(y=1):0.9938\n",
      "训练集合上的召回率(y=1):0.9918\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 基于随机森林获取影响放贷的二十大因素\n",
    "feature_importances = forest.feature_importances_\n",
    "feature_importances = 100.0 * (feature_importances / feature_importances.max())\n",
    "\n",
    "indices = np.argsort(feature_importances)[-20:]\n",
    "plt.barh(np.arange(20), feature_importances[indices], color='dodgerblue', alpha=0.4)\n",
    "plt.yticks(np.arange(20 + 0.25), np.array(X.columns)[indices])\n",
    "plt.xlabel('特征重要性百分比')\n",
    "plt.title('随机森林20大重要特征提取')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重大于0的特征数目:41\n",
      "权重等于0的特征数目:14\n",
      "权重小于0的特征数目:0\n"
     ]
    }
   ],
   "source": [
    "print(\"权重大于0的特征数目:{}\".format(np.sum(forest.feature_importances_ > 0)))\n",
    "print(\"权重等于0的特征数目:{}\".format(np.sum(forest.feature_importances_ == 0)))\n",
    "print(\"权重小于0的特征数目:{}\".format(np.sum(forest.feature_importances_ < 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始样本大小:(31828, 55)\n",
      "原始样本大小:(31828, 41)\n"
     ]
    }
   ],
   "source": [
    "# 用随机森林选择特征，然后使用Logistic回归来做预测\n",
    "weight = {\n",
    "    0: 3, # 在模型训练和测试的过程中，类别0的重要性\n",
    "    1: 1 # 在模型训练和测试的过程中，类别1的重要性\n",
    "}\n",
    "# a. 特征选择过程\n",
    "print(\"原始样本大小:{}\".format(x_train.shape))\n",
    "forest = RandomForestClassifier(random_state=0, max_depth=5, class_weight=weight)\n",
    "# 当特征的权重大于等于给定的threshold的时候，该特征就保留；由于随机森林中的特征属性权重一定是大于等于0的值，所以一般情况下，，\n",
    "# 在决策树类型的算法中，使用SelectFromModel一般选择比0稍大一点点的阈值。\n",
    "sm = SelectFromModel(estimator=forest, threshold=0.0000001)\n",
    "sm.fit(x_train, y_train)\n",
    "x_train1 = sm.transform(x_train)\n",
    "x_test1 = sm.transform(x_test)\n",
    "print(\"原始样本大小:{}\".format(x_train1.shape))\n",
    "# b. logistic回归训练\n",
    "lr = LogisticRegression(C = 0.1, class_weight=weight, fit_intercept=True, max_iter=100, penalty='l1', random_state=0)\n",
    "lr.fit(x_train1, y_train)\n",
    "\n",
    "train_predict = lr.predict(x_train1)\n",
    "test_predict = lr.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据混淆矩阵:\n",
      "[[ 1255  3272]\n",
      " [ 2594 24707]]\n",
      "\n",
      "训练数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.28      0.30      4527\n",
      "         1.0       0.88      0.90      0.89     27301\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     31828\n",
      "   macro avg       0.60      0.59      0.60     31828\n",
      "weighted avg       0.80      0.82      0.81     31828\n",
      "\n",
      "\n",
      "测试数据混淆矩阵:\n",
      "[[ 299  844]\n",
      " [ 651 6164]]\n",
      "\n",
      "测试数据分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.26      0.29      1143\n",
      "         1.0       0.88      0.90      0.89      6815\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      7958\n",
      "   macro avg       0.60      0.58      0.59      7958\n",
      "weighted avg       0.80      0.81      0.80      7958\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_train, train_predict)))\n",
    "print(\"训练数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_train, train_predict)))\n",
    "print(\"测试数据混淆矩阵:\\n{}\\n\".format(metrics.confusion_matrix(y_test, test_predict)))\n",
    "print(\"测试数据分类报告:\\n{}\\n\".format(metrics.classification_report(y_test, test_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.8953\n",
      "测试集合上的f1指标:0.8909\n",
      "训练集合上的召回率(y=0):0.2691\n",
      "训练集合上的召回率(y=0):0.2450\n",
      "训练集合上的召回率(y=1):0.9087\n",
      "训练集合上的召回率(y=1):0.9051\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GBDT的提取的效果\n",
    "gbdt = GradientBoostingClassifier(min_samples_split=50, max_depth=2, n_estimators=300, learning_rate=0.1, random_state=0)\n",
    "gbdt.fit(x_train, y_train)\n",
    "\n",
    "train_predict = gbdt.predict(x_train)\n",
    "test_predict = gbdt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.9249\n",
      "测试集合上的f1指标:0.9228\n",
      "训练集合上的召回率(y=0):0.0320\n",
      "训练集合上的召回率(y=0):0.0262\n",
      "训练集合上的召回率(y=1):0.9984\n",
      "训练集合上的召回率(y=1):0.9966\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 基于GBDT获取影响放贷的二十大因素\n",
    "feature_importances = gbdt.feature_importances_\n",
    "feature_importances = 100.0 * (feature_importances / feature_importances.max())\n",
    "\n",
    "indices = np.argsort(feature_importances)[-20:]\n",
    "plt.barh(np.arange(20), feature_importances[indices], color='dodgerblue', alpha=0.4)\n",
    "plt.yticks(np.arange(20 + 0.25), np.array(X.columns)[indices])\n",
    "plt.xlabel('特征重要性百分比')\n",
    "plt.title('GBDT 20大重要特征提取')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "权重大于0的特征数目:38\n",
      "权重等于0的特征数目:17\n",
      "权重小于0的特征数目:0\n"
     ]
    }
   ],
   "source": [
    "print(\"权重大于0的特征数目:{}\".format(np.sum(gbdt.feature_importances_ > 0)))\n",
    "print(\"权重等于0的特征数目:{}\".format(np.sum(gbdt.feature_importances_ == 0)))\n",
    "print(\"权重小于0的特征数目:{}\".format(np.sum(gbdt.feature_importances_ < 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: 实现以下使用GBDT提取特征(维度扩展)，提取出来的特征使用Logistic回归做一个分类，看一下模型效果如何\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后样本大小:(31828, 40)\n"
     ]
    }
   ],
   "source": [
    "# 在实际工作中，如果发现模型的效果不如意，那么可能需要考虑特征选择和降维\n",
    "# 使用逻辑回归来分析数据 + 特征选择 + 降维\n",
    "# 特征选择：从所有特征属性中抽取出来影响目标属性(target)效果最大的特征属性作为下一步的特征属性列表\\\n",
    "# 很多特征选择工程都是选择方差比较大特征属性\n",
    "# 也可以使用随机森林、GBDT、决策树来进行特征选择\n",
    "\n",
    "# 降维：压缩样本的维度空间，直白来讲，就是讲DataFrame中原本的多个列合并成为一列\n",
    "\n",
    "# 1. 特征选择\n",
    "feature_importances = gbdt.feature_importances_\n",
    "indices = np.argsort(feature_importances)[-30:]\n",
    "top30_features = np.array(X.columns)[indices]\n",
    "\n",
    "# 2. 提取影响最大的三十个特征属性\n",
    "x_train2 = x_train[top30_features]\n",
    "x_test2 = x_test[top30_features]\n",
    "\n",
    "# 3. 降维处理(在三十个特征之外，将其它的特征数据做一个降维操作)\n",
    "x_train3 = x_train.drop(top30_features, 1, inplace=False)\n",
    "x_test3 = x_test.drop(top30_features, 1, inplace=False)\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x_train3)\n",
    "x_test3 = pca.transform(x_test3)\n",
    "x_train3 = pca.transform(x_train3)\n",
    "\n",
    "# 4. 两个DataFrame合并\n",
    "x_train2 = np.hstack([x_train2, x_train3])\n",
    "x_test2 = np.hstack([x_test2, x_test3])\n",
    "print(\"合并后样本大小:{}\".format(x_train2.shape))\n",
    "\n",
    "weight = {\n",
    "    0: 3, # 在模型训练和测试的过程中，类别0的重要性\n",
    "    1: 1 # 在模型训练和测试的过程中，类别1的重要性\n",
    "}\n",
    "lr = LogisticRegression(C = 0.1,class_weight=weight, fit_intercept=True, max_iter=100, penalty='l1', random_state=0)\n",
    "lr.fit(x_train2, y_train)\n",
    "\n",
    "train_predict = lr.predict(x_train2)\n",
    "test_predict = lr.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集合上的f1指标:0.8940\n",
      "测试集合上的f1指标:0.8926\n",
      "训练集合上的召回率(y=0):0.2770\n",
      "训练集合上的召回率(y=0):0.2686\n",
      "训练集合上的召回率(y=1):0.9052\n",
      "训练集合上的召回率(y=1):0.9049\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集合上的f1指标:%.4f\" % f1_score(y_train, train_predict))\n",
    "print(\"测试集合上的f1指标:%.4f\" % f1_score(y_test, test_predict))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_train, train_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=0):%.4f\" % recall_score(y_test, test_predict, pos_label=0))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_train, train_predict, pos_label=1))\n",
    "print(\"训练集合上的召回率(y=1):%.4f\" % recall_score(y_test, test_predict, pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算KS指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集 KS: 0.27886314284082064\n"
     ]
    }
   ],
   "source": [
    "# 计算KS的方式一：\n",
    "def compute_ks(data):\n",
    "    # 按照样本为正样本的概率值升序排序 ，也即坏样本的概率从高到低排序\n",
    "    sorted_list = data.sort_values(['predict_proba'], ascending=[True])\n",
    "    total_good = sorted_list['label'].sum()\n",
    "    total_bad = sorted_list.shape[0] - total_good  \n",
    "    \n",
    "    max_ks = 0.0\n",
    "    good_count = 0.0\n",
    "    bad_count = 0.0\n",
    "    bads = []\n",
    "    goods = []\n",
    "    for index, row in sorted_list.iterrows(): #按照标签和每行拆开\n",
    "        if row['label'] == 0:\n",
    "            bad_count +=1\n",
    "        else:\n",
    "            good_count +=1\n",
    "        val = abs(bad_count/total_bad - good_count/total_good)\n",
    "        if index % 100 == 0:\n",
    "            bads.append(bad_count/total_bad)\n",
    "            goods.append(good_count/total_good)\n",
    "        max_ks = max(max_ks, val)\n",
    "    # 可视化画图\n",
    "    plt.plot(range(len(bads)), bads, 'r-o')\n",
    "    plt.plot(range(len(goods)), goods, 'g-o')\n",
    "    plt.show()\n",
    "    return max_ks\n",
    "\n",
    "test_pd=pd.DataFrame()\n",
    "y_predict_proba=lr.predict_proba(x_test2)[:,1] #取被分为正样本的概率那一列\n",
    "Y_test_1=np.array(y_test)\n",
    "test_pd['label']=Y_test_1\n",
    "test_pd['predict_proba']=y_predict_proba\n",
    "print (\"测试集 KS:\",compute_ks(test_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS: 0.2788631428408206\n"
     ]
    }
   ],
   "source": [
    "# 计算KS的方式二\n",
    "y_predict_proba = lr.predict_proba(x_test2)[:,1]\n",
    "fpr,tpr,thresholds= sklearn.metrics.roc_curve(np.array(y_test),y_predict_proba)\n",
    "print ('KS:',max(tpr-fpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
